{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 154</th>\n",
       "      <th>Unnamed: 155</th>\n",
       "      <th>Unnamed: 156</th>\n",
       "      <th>Unnamed: 157</th>\n",
       "      <th>Unnamed: 158</th>\n",
       "      <th>Unnamed: 159</th>\n",
       "      <th>Unnamed: 160</th>\n",
       "      <th>Unnamed: 161</th>\n",
       "      <th>Unnamed: 162</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-57.643410</td>\n",
       "      <td>-69.255959</td>\n",
       "      <td>-69.413849</td>\n",
       "      <td>-68.149704</td>\n",
       "      <td>-66.578133</td>\n",
       "      <td>-64.643143</td>\n",
       "      <td>-62.542328</td>\n",
       "      <td>-63.937115</td>\n",
       "      <td>-68.589905</td>\n",
       "      <td>-72.532310</td>\n",
       "      <td>...</td>\n",
       "      <td>-93.558609</td>\n",
       "      <td>-93.287292</td>\n",
       "      <td>-92.827217</td>\n",
       "      <td>-93.226494</td>\n",
       "      <td>-93.012207</td>\n",
       "      <td>-92.636810</td>\n",
       "      <td>-91.491699</td>\n",
       "      <td>-91.801826</td>\n",
       "      <td>-92.639168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-61.877784</td>\n",
       "      <td>-74.343368</td>\n",
       "      <td>-74.512856</td>\n",
       "      <td>-73.155850</td>\n",
       "      <td>-71.468834</td>\n",
       "      <td>-69.391703</td>\n",
       "      <td>-67.136567</td>\n",
       "      <td>-68.633812</td>\n",
       "      <td>-73.628387</td>\n",
       "      <td>-77.860393</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.431244</td>\n",
       "      <td>-100.139996</td>\n",
       "      <td>-99.646125</td>\n",
       "      <td>-100.074732</td>\n",
       "      <td>-99.844704</td>\n",
       "      <td>-99.441731</td>\n",
       "      <td>-98.212502</td>\n",
       "      <td>-98.545411</td>\n",
       "      <td>-99.444262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-57.906037</td>\n",
       "      <td>-69.571493</td>\n",
       "      <td>-69.730102</td>\n",
       "      <td>-68.460198</td>\n",
       "      <td>-66.881467</td>\n",
       "      <td>-64.937661</td>\n",
       "      <td>-62.827274</td>\n",
       "      <td>-64.228416</td>\n",
       "      <td>-68.902405</td>\n",
       "      <td>-72.862771</td>\n",
       "      <td>...</td>\n",
       "      <td>-93.984867</td>\n",
       "      <td>-93.712314</td>\n",
       "      <td>-93.250143</td>\n",
       "      <td>-93.651239</td>\n",
       "      <td>-93.435976</td>\n",
       "      <td>-93.058869</td>\n",
       "      <td>-91.908540</td>\n",
       "      <td>-92.220080</td>\n",
       "      <td>-93.061237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-57.361297</td>\n",
       "      <td>-68.917013</td>\n",
       "      <td>-69.074130</td>\n",
       "      <td>-67.816172</td>\n",
       "      <td>-66.252293</td>\n",
       "      <td>-64.326773</td>\n",
       "      <td>-62.236239</td>\n",
       "      <td>-63.624200</td>\n",
       "      <td>-68.254219</td>\n",
       "      <td>-72.177329</td>\n",
       "      <td>...</td>\n",
       "      <td>-93.100723</td>\n",
       "      <td>-92.830734</td>\n",
       "      <td>-92.372911</td>\n",
       "      <td>-92.770234</td>\n",
       "      <td>-92.556996</td>\n",
       "      <td>-92.183436</td>\n",
       "      <td>-91.043929</td>\n",
       "      <td>-91.352538</td>\n",
       "      <td>-92.185782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-53.705822</td>\n",
       "      <td>-64.525125</td>\n",
       "      <td>-64.672229</td>\n",
       "      <td>-63.494437</td>\n",
       "      <td>-62.030219</td>\n",
       "      <td>-60.227407</td>\n",
       "      <td>-58.270098</td>\n",
       "      <td>-59.569608</td>\n",
       "      <td>-63.904568</td>\n",
       "      <td>-67.577670</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.167675</td>\n",
       "      <td>-86.914891</td>\n",
       "      <td>-86.486244</td>\n",
       "      <td>-86.858246</td>\n",
       "      <td>-86.658597</td>\n",
       "      <td>-86.308843</td>\n",
       "      <td>-85.241954</td>\n",
       "      <td>-85.530897</td>\n",
       "      <td>-86.311040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  \\\n",
       "0  -57.643410  -69.255959  -69.413849  -68.149704  -66.578133  -64.643143   \n",
       "1  -61.877784  -74.343368  -74.512856  -73.155850  -71.468834  -69.391703   \n",
       "2  -57.906037  -69.571493  -69.730102  -68.460198  -66.881467  -64.937661   \n",
       "3  -57.361297  -68.917013  -69.074130  -67.816172  -66.252293  -64.326773   \n",
       "4  -53.705822  -64.525125  -64.672229  -63.494437  -62.030219  -60.227407   \n",
       "\n",
       "   Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  Unnamed: 154  \\\n",
       "0  -62.542328  -63.937115  -68.589905  -72.532310  ...    -93.558609   \n",
       "1  -67.136567  -68.633812  -73.628387  -77.860393  ...   -100.431244   \n",
       "2  -62.827274  -64.228416  -68.902405  -72.862771  ...    -93.984867   \n",
       "3  -62.236239  -63.624200  -68.254219  -72.177329  ...    -93.100723   \n",
       "4  -58.270098  -59.569608  -63.904568  -67.577670  ...    -87.167675   \n",
       "\n",
       "   Unnamed: 155  Unnamed: 156  Unnamed: 157  Unnamed: 158  Unnamed: 159  \\\n",
       "0    -93.287292    -92.827217    -93.226494    -93.012207    -92.636810   \n",
       "1   -100.139996    -99.646125   -100.074732    -99.844704    -99.441731   \n",
       "2    -93.712314    -93.250143    -93.651239    -93.435976    -93.058869   \n",
       "3    -92.830734    -92.372911    -92.770234    -92.556996    -92.183436   \n",
       "4    -86.914891    -86.486244    -86.858246    -86.658597    -86.308843   \n",
       "\n",
       "   Unnamed: 160  Unnamed: 161  Unnamed: 162  label  \n",
       "0    -91.491699    -91.801826    -92.639168      0  \n",
       "1    -98.212502    -98.545411    -99.444262      0  \n",
       "2    -91.908540    -92.220080    -93.061237      0  \n",
       "3    -91.043929    -91.352538    -92.185782      0  \n",
       "4    -85.241954    -85.530897    -86.311040      0  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/tuandinh/Desktop/Demo/data_final.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data_frame.iloc[index, :].values.astype(float)\n",
    "\n",
    "        # The last column can be the target label (0 for no defect, 1 for defect)\n",
    "        # You can adjust this based on your actual data structure\n",
    "        target = int(sample[-1])\n",
    "\n",
    "        # Remove the target label from the sample\n",
    "        sample = sample[:-1]\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        sample = torch.FloatTensor(sample)\n",
    "        # print(f\"Length of sample {len(sample)}\")\n",
    "        target = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "        # Apply the optional data transformation\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "# Path to your merged CSV file\n",
    "# csv_merged = '/home/tuandinh/Desktop/Signal Classification/data_signal.csv'\n",
    "csv_merged = '/home/tuandinh/Desktop/Demo/data_final.csv'\n",
    "# Create an instance of the custom dataset\n",
    "custom_dataset = SignalDataset(csv_merged)\n",
    "# test_dataset = SignalDataset(csv_test_path)\n",
    "\n",
    "# # Create a data loader for the dataset\n",
    "# batch_size = 32\n",
    "# train_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a perceptron \n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(163, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)   \n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleClassifier(\n",
       "  (fc1): Linear(in_features=163, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "input_size = 163  # Number of features in your data\n",
    "hidden_size = 64  # Number of hidden units in the neural network\n",
    "num_classes = 2  # Number of classes (0 for no defect, 1 for defect)\n",
    "learning_rate = 0.000001\n",
    "num_epochs = 100\n",
    "\n",
    "# Split your dataset into training and validation sets\n",
    "train_dataset, val_dataset = train_test_split(custom_dataset, train_size=0.8,  test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Create data loaders for training and validation\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleClassifier(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.0\n",
    "    lass_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        input, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "    return lass_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0 valid 0.5729912519454956\n",
      "EPOCH 2:\n",
      "LOSS train 0 valid 0.5760024785995483\n",
      "EPOCH 3:\n",
      "LOSS train 0 valid 0.5651397109031677\n",
      "EPOCH 4:\n",
      "LOSS train 0 valid 0.5565993189811707\n",
      "EPOCH 5:\n",
      "LOSS train 0 valid 0.5346755981445312\n",
      "EPOCH 6:\n",
      "LOSS train 0 valid 0.5291065573692322\n",
      "EPOCH 7:\n",
      "LOSS train 0 valid 0.5236575603485107\n",
      "EPOCH 8:\n",
      "LOSS train 0 valid 0.5328245759010315\n",
      "EPOCH 9:\n",
      "LOSS train 0 valid 0.5294938087463379\n",
      "EPOCH 10:\n",
      "LOSS train 0 valid 0.5257853865623474\n",
      "EPOCH 11:\n",
      "LOSS train 0 valid 0.5089524984359741\n",
      "EPOCH 12:\n",
      "LOSS train 0 valid 0.5064400434494019\n",
      "EPOCH 13:\n",
      "LOSS train 0 valid 0.5186223983764648\n",
      "EPOCH 14:\n",
      "LOSS train 0 valid 0.5168060660362244\n",
      "EPOCH 15:\n",
      "LOSS train 0 valid 0.515264093875885\n",
      "EPOCH 16:\n",
      "LOSS train 0 valid 0.5138176679611206\n",
      "EPOCH 17:\n",
      "LOSS train 0 valid 0.5126318335533142\n",
      "EPOCH 18:\n",
      "LOSS train 0 valid 0.5115668773651123\n",
      "EPOCH 19:\n",
      "LOSS train 0 valid 0.49656155705451965\n",
      "EPOCH 20:\n",
      "LOSS train 0 valid 0.5097765326499939\n",
      "EPOCH 21:\n",
      "LOSS train 0 valid 0.4948917031288147\n",
      "EPOCH 22:\n",
      "LOSS train 0 valid 0.5083838105201721\n",
      "EPOCH 23:\n",
      "LOSS train 0 valid 0.49368202686309814\n",
      "EPOCH 24:\n",
      "LOSS train 0 valid 0.4930359125137329\n",
      "EPOCH 25:\n",
      "LOSS train 0 valid 0.49244409799575806\n",
      "EPOCH 26:\n",
      "LOSS train 0 valid 0.49206286668777466\n",
      "EPOCH 27:\n",
      "LOSS train 0 valid 0.4916324317455292\n",
      "EPOCH 28:\n",
      "LOSS train 0 valid 0.5054060220718384\n",
      "EPOCH 29:\n",
      "LOSS train 0 valid 0.5051977038383484\n",
      "EPOCH 30:\n",
      "LOSS train 0 valid 0.5047001242637634\n",
      "EPOCH 31:\n",
      "LOSS train 0 valid 0.5045508146286011\n",
      "EPOCH 32:\n",
      "LOSS train 0 valid 0.4901130795478821\n",
      "EPOCH 33:\n",
      "LOSS train 0 valid 0.5040162205696106\n",
      "EPOCH 34:\n",
      "LOSS train 0 valid 0.5037265419960022\n",
      "EPOCH 35:\n",
      "LOSS train 0 valid 0.5034958720207214\n",
      "EPOCH 36:\n",
      "LOSS train 0 valid 0.48914635181427\n",
      "EPOCH 37:\n",
      "LOSS train 0 valid 0.5031362175941467\n",
      "EPOCH 38:\n",
      "LOSS train 0 valid 0.5029927492141724\n",
      "EPOCH 39:\n",
      "LOSS train 0 valid 0.5028151273727417\n",
      "EPOCH 40:\n",
      "LOSS train 0 valid 0.4886094927787781\n",
      "EPOCH 41:\n",
      "LOSS train 0 valid 0.48838791251182556\n",
      "EPOCH 42:\n",
      "LOSS train 0 valid 0.4882566034793854\n",
      "EPOCH 43:\n",
      "LOSS train 0 valid 0.4881228804588318\n",
      "EPOCH 44:\n",
      "LOSS train 0 valid 0.5021809339523315\n",
      "EPOCH 45:\n",
      "LOSS train 0 valid 0.48791950941085815\n",
      "EPOCH 46:\n",
      "LOSS train 0 valid 0.5019813776016235\n",
      "EPOCH 47:\n",
      "LOSS train 0 valid 0.5019425749778748\n",
      "EPOCH 48:\n",
      "LOSS train 0 valid 0.5018377304077148\n",
      "EPOCH 49:\n",
      "LOSS train 0 valid 0.4875999987125397\n",
      "EPOCH 50:\n",
      "LOSS train 0 valid 0.5016847252845764\n",
      "EPOCH 51:\n",
      "LOSS train 0 valid 0.5015886425971985\n",
      "EPOCH 52:\n",
      "LOSS train 0 valid 0.501527726650238\n",
      "EPOCH 53:\n",
      "LOSS train 0 valid 0.5014655590057373\n",
      "EPOCH 54:\n",
      "LOSS train 0 valid 0.48726433515548706\n",
      "EPOCH 55:\n",
      "LOSS train 0 valid 0.5013758540153503\n",
      "EPOCH 56:\n",
      "LOSS train 0 valid 0.5013171434402466\n",
      "EPOCH 57:\n",
      "LOSS train 0 valid 0.48712021112442017\n",
      "EPOCH 58:\n",
      "LOSS train 0 valid 0.5012302398681641\n",
      "EPOCH 59:\n",
      "LOSS train 0 valid 0.5011782050132751\n",
      "EPOCH 60:\n",
      "LOSS train 0 valid 0.48699870705604553\n",
      "EPOCH 61:\n",
      "LOSS train 0 valid 0.48696234822273254\n",
      "EPOCH 62:\n",
      "LOSS train 0 valid 0.4869067072868347\n",
      "EPOCH 63:\n",
      "LOSS train 0 valid 0.48687779903411865\n",
      "EPOCH 64:\n",
      "LOSS train 0 valid 0.5009989738464355\n",
      "EPOCH 65:\n",
      "LOSS train 0 valid 0.500975489616394\n",
      "EPOCH 66:\n",
      "LOSS train 0 valid 0.500952959060669\n",
      "EPOCH 67:\n",
      "LOSS train 0 valid 0.5009256601333618\n",
      "EPOCH 68:\n",
      "LOSS train 0 valid 0.500893235206604\n",
      "EPOCH 69:\n",
      "LOSS train 0 valid 0.4867149889469147\n",
      "EPOCH 70:\n",
      "LOSS train 0 valid 0.486705482006073\n",
      "EPOCH 71:\n",
      "LOSS train 0 valid 0.5008234977722168\n",
      "EPOCH 72:\n",
      "LOSS train 0 valid 0.5008062720298767\n",
      "EPOCH 73:\n",
      "LOSS train 0 valid 0.48663875460624695\n",
      "EPOCH 74:\n",
      "LOSS train 0 valid 0.486624538898468\n",
      "EPOCH 75:\n",
      "LOSS train 0 valid 0.48659950494766235\n",
      "EPOCH 76:\n",
      "LOSS train 0 valid 0.4865875244140625\n",
      "EPOCH 77:\n",
      "LOSS train 0 valid 0.5007274150848389\n",
      "EPOCH 78:\n",
      "LOSS train 0 valid 0.5007121562957764\n",
      "EPOCH 79:\n",
      "LOSS train 0 valid 0.4865517318248749\n",
      "EPOCH 80:\n",
      "LOSS train 0 valid 0.4865294098854065\n",
      "EPOCH 81:\n",
      "LOSS train 0 valid 0.48652249574661255\n",
      "EPOCH 82:\n",
      "LOSS train 0 valid 0.5006750822067261\n",
      "EPOCH 83:\n",
      "LOSS train 0 valid 0.48650267720222473\n",
      "EPOCH 84:\n",
      "LOSS train 0 valid 0.5006463527679443\n",
      "EPOCH 85:\n",
      "LOSS train 0 valid 0.48648494482040405\n",
      "EPOCH 86:\n",
      "LOSS train 0 valid 0.5006283521652222\n",
      "EPOCH 87:\n",
      "LOSS train 0 valid 0.5006167888641357\n",
      "EPOCH 88:\n",
      "LOSS train 0 valid 0.500608503818512\n",
      "EPOCH 89:\n",
      "LOSS train 0 valid 0.5005995631217957\n",
      "EPOCH 90:\n",
      "LOSS train 0 valid 0.486442506313324\n",
      "EPOCH 91:\n",
      "LOSS train 0 valid 0.5005903840065002\n",
      "EPOCH 92:\n",
      "LOSS train 0 valid 0.48642680048942566\n",
      "EPOCH 93:\n",
      "LOSS train 0 valid 0.4864215850830078\n",
      "EPOCH 94:\n",
      "LOSS train 0 valid 0.5005702972412109\n",
      "EPOCH 95:\n",
      "LOSS train 0 valid 0.5005624890327454\n",
      "EPOCH 96:\n",
      "LOSS train 0 valid 0.5005585551261902\n",
      "EPOCH 97:\n",
      "LOSS train 0 valid 0.48640176653862\n",
      "EPOCH 98:\n",
      "LOSS train 0 valid 0.4863947331905365\n",
      "EPOCH 99:\n",
      "LOSS train 0 valid 0.5005444884300232\n",
      "EPOCH 100:\n",
      "LOSS train 0 valid 0.4863875210285187\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/singnal_classification_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "    # validation loss\n",
    "    running_vloss = 0.0\n",
    "    model.eval()\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            val_input, vlabels = vdata\n",
    "            voutputs = model(val_input)\n",
    "            vloss = criterion(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "    \n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'models/model_{}_{}.pt'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/tuandinh/Desktop/Signal Classification/file_data_new.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tuandinh/Desktop/Demo/demo.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tuandinh/Desktop/Demo/demo.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/home/tuandinh/Desktop/Signal Classification/file_data_new.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tuandinh/Desktop/Demo/demo.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# data.shape\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tuandinh/Desktop/Demo/demo.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sample \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39miloc[\u001b[39m1\u001b[39m,:]\n",
      "File \u001b[0;32m~/Desktop/Demo/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Desktop/Demo/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/Demo/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Desktop/Demo/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/Demo/env/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/tuandinh/Desktop/Signal Classification/file_data_new.csv'"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv(\"/home/tuandinh/Desktop/Signal Classification/file_data_new.csv\")\n",
    "# # data.shape\n",
    "# sample = data.iloc[1,:]\n",
    "# input = sample[:-1]\n",
    "# label = sample[-1]\n",
    "# input = torch.tensor(input)\n",
    "# input.shape\n",
    "\n",
    "# PATH = \"/home/tuandinh/Desktop/Signal Classification/models/model_20230910_093359_0.pt\"\n",
    "# model1 = SimpleClassifier(163, 32,2)\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model.load_state_dict(checkpoint)\n",
    "# model.to(device)\n",
    "# model.eval()\n",
    "# # Thá»±c hiá»‡n dá»± Ä‘oÃ¡n\n",
    "# with torch.no_grad():\n",
    "#     predicted = model(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
